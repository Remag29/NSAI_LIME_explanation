# Projet 2

## Question 1

> Provide a brief study of XAI tools used in the following paper : "Mane, Shraddha & Rao, Dattaraj. (2021). Explaining Network Intrusion Detection System Using Explainable AI Framework."

The document proposes the use of several explainable AI (XAI) tools for network intrusion detection systems. These tools include SHAP, LIME, Contrastive Explanation Method (CEM), ProtoDash, and Boolean Decision Rules via Column Generation (BRCG). The purpose of these XAI algorithms is to make machine learning models in intrusion detection systems more transparent and provide explanations for their decisions.
For data scientists, the document suggests using explainable AI methods such as SHAP, BRCG, and ProtoDash to gain global understanding of the model’s behavior. Analysts can utilize the Protodash method to explore and compare similar instances from the training dataset. Meanwhile, end users can benefit from local explanation techniques like LIME, SHAP, and CEM to understand which features contribute to the model’s decisions and how changing the feature values can affect the model’s output.
The document emphasizes the importance of interpretability in deep learning models, which are often considered as black boxes. By utilizing the proposed explainable AI framework, the document aims to provide explanations at every stage of the machine learning pipeline, ensuring transparency and enabling users to understand the model’s predictions. The ultimate goal is to make network intrusion detection systems more trustworthy and usable in real-world applications.

